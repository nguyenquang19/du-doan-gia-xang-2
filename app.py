import pandas as pd
import numpy as np
import streamlit as st
import os
import matplotlib.pyplot as plt

# --- Imports cho c√°c m√¥ h√¨nh Scikit-learn ---
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

# --- Imports cho c√°c m√¥ h√¨nh b√™n ngo√†i (C·∫¶N PH·∫¢I C√ÄI ƒê·∫∂T B·∫∞NG PIP) ---
try:
    import xgboost as xgb
    XGBRegressor = xgb.XGBRegressor
except Exception:
    XGBRegressor = None

try:
    import lightgbm as lgb
    LGBMRegressor = lgb.LGBMRegressor
except Exception:
    LGBMRegressor = None

try:
    import catboost as cat
    CatBoostRegressor = cat.CatBoostRegressor
except Exception:
    CatBoostRegressor = None

# -----------------------------------------------------------------------------------
# THAM S·ªê C·∫§U H√åNH V√Ä T√äN FILE
# -----------------------------------------------------------------------------------
RAW_DATA_FILE = "Data_tho_chua_xu_ly.csv"
TARGET_COL = 'RON 95-III(VND)'
TEST_SIZE = 150
LAG_W = [1, 7]
VOL_W = 7
EVENT_LAG = [3, 7]

EVENT_MAP = {
    'Cung (OPEC & S·∫£n l∆∞·ª£ng)': 'event_Cung (OPEC & S·∫£n l∆∞·ª£ng)',
    'Cung (T·ªìn kho M·ªπ)': 'event_Cung (T·ªìn kho M·ªπ)',
    'C·∫ßu (Kinh t·∫ø vƒ© m√¥)': 'event_C·∫ßu (Kinh t·∫ø vƒ© m√¥)',
    'S·ª± c·ªë & Gi√°n ƒëo·∫°n': 'event_S·ª± c·ªë & Gi√°n ƒëo·∫°n',
    'ƒê·ªãa ch√≠nh tr·ªã & Xung ƒë·ªôt': 'event_ƒê·ªãa ch√≠nh tr·ªã & Xung ƒë·ªôt',
    'ƒê·ªìng USD & T√†i ch√≠nh': 'event_ƒê·ªìng USD & T√†i ch√≠nh'
}

# -----------------------------------------------------------------------------------
# A. H√ÄM FEATURE ENGINEERING V√Ä SCALING (AN TO√ÄN V·ªöI T√äN C·ªòT)
# -----------------------------------------------------------------------------------
def create_features(df_raw, scaler=None, fit_scaler=False):
    """Th·ª±c hi·ªán to√†n b·ªô qu√° tr√¨nh Feature Engineering v√† Scaling/Transforming.
    Tr·∫£ v·ªÅ:
      - n·∫øu fit_scaler=True: (X_scaled_df, y_series, scaler)
      - elif scaler provided: (X_scaled_df, y_series)
      - else: (X_features_df, y_series)
    """
    df = df_raw.copy().reset_index(drop=True)
    df.columns = df.columns.astype(str)

    # ƒë·∫£m b·∫£o c√≥ c·ªôt date
    if 'date' not in df.columns:
        raise ValueError("Column 'date' kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu ƒë·∫ßu v√†o.")

    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date').reset_index(drop=True)

    # Fill forward/backward c√°c c·ªôt gi√° quan tr·ªçng n·∫øu t·ªìn t·∫°i
    cols_to_fill = [c for c in ['Gia_Brent(USD)', 'Gia_WTI(USD)', 'USD/VND', 'Bien_loi_nhuan'] if c in df.columns]
    if cols_to_fill:
        df[cols_to_fill] = df[cols_to_fill].ffill().bfill()

    # Drop c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt n·∫øu t·ªìn t·∫°i
    for c in ['E5 RON 92-II(VND)', 'Bien_loi_nhuan']:
        if c in df.columns:
            df = df.drop(columns=[c])

    # C√°c c·ªôt gi√° c∆° b·∫£n ‚Äî ki·ªÉm tra t·ªìn t·∫°i
    price_cols = [c for c in ['Gia_Brent(USD)', 'Gia_WTI(USD)', 'USD/VND'] if c in df.columns]
    if not price_cols:
        raise ValueError("Kh√¥ng t√¨m th·∫•y c·ªôt gi√° n√†o trong d·ªØ li·ªáu (Gia_Brent/WTI/USD/VND).")

    # T·∫°o lag, pct change, volatility
    for col in price_cols:
        base = col.split("(")[0].rstrip()
        # lags
        for lag in LAG_W:
            df[f'{base}_lag{lag}'] = df[col].shift(lag)
        # percent change
        df[f'{base}_pct'] = df[col].pct_change()
        # rolling volatility
        df[f'{base}_vol{VOL_W}'] = df[col].rolling(window=VOL_W, min_periods=1).std()

    # S·ª± ki·ªán v√† sentiment: chu·∫©n h√≥a c·ªôt c√≥ th·ªÉ thi·∫øu
    if 'loai_su_kien' not in df.columns:
        df['loai_su_kien'] = np.nan
    if 'tang_giam' not in df.columns:
        df['tang_giam'] = np.nan
    if 'ten_su_kien' not in df.columns:
        df['ten_su_kien'] = np.nan

    df['loai_su_kien'] = df['loai_su_kien'].fillna('No_Event')
    df['tang_giam'] = df['tang_giam'].fillna('None')

    # One-hot event categories; ƒë·∫£m b·∫£o c√≥ ƒë·ªß c√°c c·ªôt theo EVENT_MAP
    event_dummies = pd.get_dummies(df['loai_su_kien'].astype(str)).astype(int)
    # rename keys present to our standardized names
    rename_map = {k: v for k, v in EVENT_MAP.items() if k in event_dummies.columns}
    if rename_map:
        event_dummies = event_dummies.rename(columns=rename_map)
    # add any missing event columns with zeros
    for std_col in EVENT_MAP.values():
        if std_col not in event_dummies.columns:
            event_dummies[std_col] = 0

    # drop No_Event column if present
    if 'No_Event' in event_dummies.columns:
        event_dummies = event_dummies.drop(columns=['No_Event'])

    df['event_impact'] = (df['loai_su_kien'] != 'No_Event').astype(int)

    sentiment_map = {'Gi·∫£m': -1, 'TƒÉng': 1, 'None': 0}
    df['sentiment_score'] = df['tang_giam'].map(sentiment_map).fillna(0).astype(int)
    df['event_sentiment_7'] = df['sentiment_score'].rolling(window=VOL_W, min_periods=1).sum()
    # Now event lag features (rolling sum of event_impact shifted by 1 day)
    for lag in EVENT_LAG:
        df[f'event_lag_{lag}'] = df['event_impact'].shift(1).rolling(window=lag, min_periods=1).sum().fillna(0).astype(int)

    # Combine features: drop textual columns
    drop_cols = [c for c in ['loai_su_kien', 'tang_giam', 'ten_su_kien'] if c in df.columns]
    df_features = pd.concat([df.drop(columns=drop_cols + [TARGET_COL] if TARGET_COL in df.columns else drop_cols, errors='ignore'),
                             event_dummies.reset_index(drop=True)], axis=1)

    # Drop rows with NaN in essential feature columns (after creating lags)
    df_features = df_features.dropna().reset_index(drop=True)

    # Target series (aligned with df_features index)
    if TARGET_COL in df.columns:
        y_raw = df.loc[df_features.index, TARGET_COL].reset_index(drop=True)
    else:
        # n·∫øu kh√¥ng c√≥ target trong df (v√≠ d·ª• khi th√™m h√†ng input ch∆∞a c√≥ gi√°), t·∫°o series NaN
        y_raw = pd.Series([np.nan] * len(df_features), name=TARGET_COL)

    # Final X (drop date column from features but keep as index)
    if 'date' in df_features.columns:
        X_features = df_features.drop(columns=['date'])
    else:
        X_features = df_features.copy()

    # Standard scaling when y√™u c·∫ßu
    if fit_scaler:
        scaler_obj = StandardScaler()
        X_scaled = scaler_obj.fit_transform(X_features)
        X_scaled_df = pd.DataFrame(X_scaled, columns=X_features.columns)
        return X_scaled_df, y_raw, scaler_obj

    if scaler is not None:
        X_scaled = scaler.transform(X_features)
        X_scaled_df = pd.DataFrame(X_scaled, columns=X_features.columns)
        return X_scaled_df, y_raw

    return X_features, y_raw

# -----------------------------------------------------------------------------------
# B. H√ÄM T·∫¢I V√Ä HU·∫§N LUY·ªÜN NHI·ªÄU M√î H√åNH
# -----------------------------------------------------------------------------------
@st.cache_resource
def load_and_train_model():
    """T·∫£i d·ªØ li·ªáu, chu·∫©n b·ªã, v√† hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh."""
    if not os.path.exists(RAW_DATA_FILE):
        st.error(f"File dataset '{RAW_DATA_FILE}' kh√¥ng t√¨m th·∫•y.")
        return None, None, None, None, None

    df_raw = pd.read_csv(RAW_DATA_FILE)
    df_raw.columns = df_raw.columns.astype(str)

    # Fit scaler v√† t·∫°o feature matrix
    try:
        X_scaled, y_raw, scaler = create_features(df_raw, fit_scaler=True)
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o feature: {e}")
        return None, None, None, None, None

    # train/test split (index based on sorted date prior)
    if len(X_scaled) <= TEST_SIZE + 10:
        st.warning("D·ªØ li·ªáu qu√° √≠t so v·ªõi TEST_SIZE ‚Äî gi·∫£m TEST_SIZE ho·∫∑c b·ªï sung d·ªØ li·ªáu.")
    X_train = X_scaled.iloc[:-TEST_SIZE]
    X_test = X_scaled.iloc[-TEST_SIZE:]
    y_train = y_raw.iloc[:-TEST_SIZE]
    y_test = y_raw.iloc[-TEST_SIZE:]

    models = {
        "Random Forest Regressor": RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1),
        "Gradient Boosting Regressor": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),
        "Linear Regression": LinearRegression(),
        "Ridge Regression": Ridge(alpha=1.0, random_state=42),
    }

    if XGBRegressor is not None:
        models["XGBoost Regressor"] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)
    if LGBMRegressor is not None:
        models["LightGBM Regressor"] = LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1)
    if CatBoostRegressor is not None:
        models["CatBoost Regressor"] = CatBoostRegressor(iterations=100, random_state=42, verbose=0)

    model_results = {}
    for name, model in models.items():
        try:
            model.fit(X_train, y_train.values)
            y_pred_test = model.predict(X_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
            model_results[name] = {'model': model, 'rmse': rmse}
        except Exception as e:
            # Kh√¥ng d·ª´ng to√†n b·ªô pipeline n·∫øu 1 model l·ªói
            st.warning(f"Kh√¥ng th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh {name}. L·ªói: {e}")

    if not model_results:
        st.error("Kh√¥ng c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán th√†nh c√¥ng.")
        return None, None, None, None, None

    best_model_name = min(model_results, key=lambda k: model_results[k]['rmse'])
    feature_names = X_scaled.columns.tolist()

    return model_results, best_model_name, feature_names, scaler, df_raw

# -----------------------------------------------------------------------------------
# C. H√ÄM D·ª∞ ƒêO√ÅN V·ªöI INPUT TH√î (Single-step)
# -----------------------------------------------------------------------------------
def predict_raw_input(raw_input_dict, df_raw_full, feature_names, scaler, selected_model):
    """D·ª± ƒëo√°n t·ª´ input th√¥ c·ªßa ng∆∞·ªùi d√πng (1 b∆∞·ªõc)."""
    # t·∫°o b·∫£n sao d·ªØ li·ªáu l·ªãch s·ª≠ v√† th√™m 1 h√†ng input (kh√¥ng l√†m thay ƒë·ªïi df_raw_full g·ªëc)
    df_history = df_raw_full.copy().reset_index(drop=True)
    new_row = {
        'date': pd.to_datetime(raw_input_dict.get('date')),
        'Gia_Brent(USD)': raw_input_dict.get('Gia_Brent(USD)', np.nan),
        'Gia_WTI(USD)': raw_input_dict.get('Gia_WTI(USD)', np.nan),
        'USD/VND': raw_input_dict.get('USD/VND', np.nan),
        'loai_su_kien': raw_input_dict.get('loai_su_kien', np.nan),
        'ten_su_kien': raw_input_dict.get('ten_su_kien', np.nan),
        'tang_giam': raw_input_dict.get('tang_giam', np.nan),
        # target and other numeric fields can be NaN
        'E5 RON 92-II(VND)': np.nan,
        'RON 95-III(VND)': np.nan,
        'Bien_loi_nhuan': np.nan
    }
    df_history = pd.concat([df_history, pd.DataFrame([new_row])], ignore_index=True)

    # t·∫°o features (s·ª≠ d·ª•ng scaler ƒë√£ fit)
    X_full, _ = create_features(df_history, scaler=scaler, fit_scaler=False)
    # L·∫•y h√†ng d·ª± ƒëo√°n cu·ªëi c√πng
    X_predict = X_full.iloc[[-1]]
    # ƒë·∫£m b·∫£o c√πng th·ª© t·ª± feature_names
    X_predict = X_predict.reindex(columns=feature_names, fill_value=0)
    raw_prediction = selected_model.predict(X_predict)[0]
    return raw_prediction, X_predict

# -----------------------------------------------------------------------------------
# D. H√ÄM D·ª∞ B√ÅO ƒê·ªÜ QUY V√Ä BOOTSTRAP CI (Multi-step Forecast)
# -----------------------------------------------------------------------------------
def recursive_forecast(df_raw_full, feature_names, scaler, selected_model, forecast_steps=30, n_bootstraps=30, st_container=None):
    """D·ª± b√°o ƒë·ªá quy v√† ∆∞·ªõc l∆∞·ª£ng CI b·∫±ng bootstrap.
       N·∫øu truy·ªÅn st_container (v√≠ d·ª• st) s·∫Ω hi·ªán progress bar.
    """
    from collections import OrderedDict

    df_history = df_raw_full.copy().reset_index(drop=True)
    # ƒë·∫£m b·∫£o c√≥ c·ªôt date
    df_history['date'] = pd.to_datetime(df_history['date'])
    df_history = df_history.sort_values('date').reset_index(drop=True)

    all_predictions = OrderedDict()

    progress = None
    if st_container is not None:
        progress = st_container.progress(0)

    for step in range(1, forecast_steps + 1):
        # next date
        last_date = df_history['date'].iloc[-1]
        next_date = last_date + pd.Timedelta(days=1)

        # Prepare next input by carrying forward last known numeric macro values and event info.
        next_input = {
            'date': next_date,
            'Gia_Brent(USD)': df_history['Gia_Brent(USD)'].iloc[-1] if 'Gia_Brent(USD)' in df_history.columns else np.nan,
            'Gia_WTI(USD)': df_history['Gia_WTI(USD)'].iloc[-1] if 'Gia_WTI(USD)' in df_history.columns else np.nan,
            'USD/VND': df_history['USD/VND'].iloc[-1] if 'USD/VND' in df_history.columns else np.nan,
            'loai_su_kien': df_history['loai_su_kien'].iloc[-1] if 'loai_su_kien' in df_history.columns else np.nan,
            'ten_su_kien': np.nan,
            'tang_giam': df_history['tang_giam'].iloc[-1] if 'tang_giam' in df_history.columns else np.nan,
            'E5 RON 92-II(VND)': np.nan,
            'RON 95-III(VND)': np.nan,
            'Bien_loi_nhuan': np.nan
        }

        # append new input (without target) so feature builder can compute lags
        df_history = pd.concat([df_history, pd.DataFrame([next_input])], ignore_index=True)

        # bootstrap predictions
        bootstrap_preds = []
        for i in range(n_bootstraps):
            X_full, _ = create_features(df_history, scaler=scaler, fit_scaler=False)
            X_predict = X_full.iloc[[-1]].reindex(columns=feature_names, fill_value=0)
            pred = selected_model.predict(X_predict)[0]
            bootstrap_preds.append(pred)

        mean_pred = float(np.mean(bootstrap_preds))
        lower_ci = float(np.percentile(bootstrap_preds, 2.5))
        upper_ci = float(np.percentile(bootstrap_preds, 97.5))

        all_predictions[next_date] = {'Gi√° D·ª± b√°o': mean_pred, 'CI 95% Min': lower_ci, 'CI 95% Max': upper_ci}

        # fill predicted mean v√†o l·ªãch s·ª≠ (cho b∆∞·ªõc ti·∫øp theo d√πng l√†m lag)
        df_history.loc[df_history.index[-1], 'RON 95-III(VND)'] = mean_pred

        if progress is not None:
            progress.progress(int(step / forecast_steps * 100))

    if progress is not None:
        progress.empty()

    df_forecast_results = pd.DataFrame.from_dict(all_predictions, orient='index')
    df_forecast_results.index.name = 'Ng√†y'
    return df_forecast_results

# -----------------------------------------------------------------------------------
# E. H√ÄM PH√ÇN T√çCH XU H∆Ø·ªöNG L·ªäCH S·ª¨ (Historical Trends)
# -----------------------------------------------------------------------------------
def plot_historical_trends(df_raw, days=90):
    df = df_raw.copy()
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date').set_index('date')

    cols_to_fill = [c for c in ['Gia_Brent(USD)', 'Gia_WTI(USD)', 'RON 95-III(VND)'] if c in df.columns]
    df[cols_to_fill] = df[cols_to_fill].ffill().bfill()

    price_cols = cols_to_fill
    df_trends = df[price_cols].tail(days)
    df_pct_change = df_trends.pct_change() * 100

    fig, ax = plt.subplots(figsize=(10, 6))
    df_norm = (df_trends / df_trends.iloc[0]) * 100
    for col in price_cols:
        ax.plot(df_norm.index, df_norm[col], label=col)

    ax.set_title(f'Xu h∆∞·ªõng Gi√° H√†ng h√≥a & XƒÉng N·ªôi ƒë·ªãa ({days} Ng√†y G·∫ßn Nh·∫•t, Chu·∫©n h√≥a)')
    ax.set_xlabel('Ng√†y')
    ax.set_ylabel('Gi√° (Chu·∫©n h√≥a, Ng√†y ƒë·∫ßu = 100)')
    ax.tick_params(axis='x', rotation=45)
    ax.legend(title='Gi√°')
    ax.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()
    return fig, df_pct_change.iloc[1:].tail(5)

# -----------------------------------------------------------------------------------
# F. H√ÄM PH√ÇN T√çCH Y·∫æU T·ªê T√ÅC ƒê·ªòNG (FEATURE IMPORTANCE)
# -----------------------------------------------------------------------------------
def get_feature_importance(model, feature_names, top_n=10):
    if hasattr(model, 'feature_importances_'):
        importance = model.feature_importances_
        df_importance = pd.DataFrame({
            'Feature': feature_names,
            'Importance': importance
        })
        df_importance = df_importance.sort_values(by='Importance', ascending=False).reset_index(drop=True)
        return df_importance.head(top_n)
    else:
        return None

# -----------------------------------------------------------------------------------
# G. H√ÄM PH√ÇN T√çCH GI√Å HI·ªÜN T·∫†I (PRICE CONTEXT)
# -----------------------------------------------------------------------------------
def get_price_context(df_raw):
    df = df_raw.copy().reset_index(drop=True)
    df.columns = df.columns.astype(str)
    if TARGET_COL not in df.columns or 'date' not in df.columns:
        return {
            'current_price': np.nan,
            'current_date': pd.NaT,
            'last_adj_date': 'N/A',
            'price_at_adj': np.nan,
            'change_from_adj': 0,
            'change_pct_from_adj': 0
        }

    latest_price = float(df[TARGET_COL].iloc[-1])
    latest_date = pd.to_datetime(df['date'].iloc[-1])

    price_changes = df[TARGET_COL].diff()
    adjustment_dates_series = df.loc[(price_changes != 0) & (price_changes.notna()), 'date']

    # prepare comparison logic safely
    if not adjustment_dates_series.empty and pd.to_datetime(adjustment_dates_series.iloc[-1]).date() == latest_date.date():
        adjustment_days_for_comparison = adjustment_dates_series.iloc[:-1]
    else:
        adjustment_days_for_comparison = adjustment_dates_series

    if (not adjustment_days_for_comparison.empty):
        last_adj_date = adjustment_days_for_comparison.iloc[-1]
        price_at_adj = float(df.loc[df['date'] == last_adj_date, TARGET_COL].iloc[0])
        change_from_adj = latest_price - price_at_adj
        change_pct_from_adj = (change_from_adj / price_at_adj) * 100 if price_at_adj != 0 else 0
    else:
        last_adj_date = 'N/A'
        price_at_adj = latest_price
        change_from_adj = 0
        change_pct_from_adj = 0

    return {
        'current_price': latest_price,
        'current_date': latest_date,
        'last_adj_date': last_adj_date,
        'price_at_adj': price_at_adj,
        'change_from_adj': change_from_adj,
        'change_pct_from_adj': change_pct_from_adj
    }

# -----------------------------------------------------------------------------------
# PH·∫¶N CH√çNH C·ª¶A STREAMLIT APP
# -----------------------------------------------------------------------------------
st.set_page_config(page_title="‚õΩ D·ª± ƒëo√°n Gi√° XƒÉng RON 95-III", layout="wide")

# T·∫£i v√† hu·∫•n luy·ªán m√¥ h√¨nh
model_results, best_model_name, feature_names, scaler, df_raw = load_and_train_model()

if df_raw is None:
    st.stop()

default_values_raw = df_raw.iloc[-1]
price_context = get_price_context(df_raw)

# Sidebar UI
st.sidebar.header("üîß C·∫•u h√¨nh M√¥ h√¨nh & ƒê·∫ßu v√†o")

# B·∫£ng so s√°nh RMSE
st.sidebar.subheader("üìä Hi·ªáu su·∫•t M√¥ h√¨nh (RMSE - VND)")
if model_results:
    rmse_data = {
        'M√¥ h√¨nh': list(model_results.keys()),
        'RMSE (VND)': [f"{model_results[name]['rmse']:,.0f}" for name in model_results.keys()]
    }
    rmse_df = pd.DataFrame(rmse_data)
    st.sidebar.dataframe(rmse_df.set_index('M√¥ h√¨nh'), use_container_width=True)
else:
    st.sidebar.write("Ch∆∞a c√≥ k·∫øt qu·∫£ m√¥ h√¨nh.")

model_selection = st.sidebar.selectbox(
    "Ch·ªçn M√¥ h√¨nh D·ª± ƒëo√°n",
    options=list(model_results.keys()),
    index=list(model_results.keys()).index(best_model_name) if model_results else 0
)

# Inputs
st.sidebar.subheader("I. Gi√° H√†ng h√≥a & T·ª∑ gi√° (TH√î)")
input_prices = {}
price_fields = [
    ('Gia_Brent(USD)', 'Gi√° Brent (USD)'),
    ('Gia_WTI(USD)', 'Gi√° WTI (USD)'),
    ('USD/VND', 'T·ª∑ gi√° USD/VND')
]
for feature_name, label in price_fields:
    default_val = float(default_values_raw[feature_name]) if feature_name in default_values_raw and not pd.isna(default_values_raw[feature_name]) else 70.0
    input_prices[feature_name] = st.sidebar.number_input(
        label, value=default_val, step=0.01, format="%.2f", key=f"raw_input_{feature_name}"
    )

st.sidebar.subheader("II. Th√¥ng tin S·ª± ki·ªán")
unique_events = list(EVENT_MAP.keys())
unique_events.insert(0, 'Kh√¥ng c√≥ s·ª± ki·ªán')
selected_event = st.sidebar.selectbox("Lo·∫°i S·ª± ki·ªán", options=unique_events, index=0)
sentiment = st.sidebar.radio("Xu h∆∞·ªõng S·ª± ki·ªán", options=['None', 'TƒÉng', 'Gi·∫£m'], index=0, disabled=(selected_event == 'Kh√¥ng c√≥ s·ª± ki·ªán'))

last_date = pd.to_datetime(df_raw.iloc[-1]['date'])
input_date = st.sidebar.date_input("Ng√†y D·ª± ƒëo√°n (Single-step)", value=last_date + pd.Timedelta(days=1), min_value=last_date + pd.Timedelta(days=1), key="input_date")

# Main UI
st.title("‚õΩ ·ª®ng d·ª•ng Ph√¢n t√≠ch & D·ª± ƒëo√°n Gi√° XƒÉng RON 95-III N·ªôi ƒë·ªãa")
st.markdown("---")

st.header("üéØ T√≥m T·∫Øt & C·∫£nh B√°o")
col1_sum, col2_sum, col3_sum = st.columns(3)

col1_sum.metric("Gi√° B√°n l·∫ª Hi·ªán t·∫°i (RON 95-III)", f"{price_context['current_price']:,.0f} VND", help=f"Gi√° ni√™m y·∫øt t·∫°i ng√†y cu·ªëi c√πng c·ªßa d·ªØ li·ªáu ({price_context['current_date'].strftime('%Y-%m-%d')})")
col2_sum.metric("So s√°nh v·ªõi K·ª≥ ƒëi·ªÅu ch·ªânh Tr∆∞·ªõc", f"{price_context['change_from_adj']:,.0f} VND", f"{price_context['change_pct_from_adj']:.2f} %", delta_color="inverse", help=f"Thay ƒë·ªïi gi√° t·ª´ ng√†y ƒëi·ªÅu ch·ªânh g·∫ßn nh·∫•t ({price_context['last_adj_date']})")

col3_sum.subheader("C·∫£nh b√°o")
if col3_sum.button("Ki·ªÉm tra c·∫£nh b√°o", key="check_warning_btn"):
    selected_model = model_results[model_selection]['model']
    raw_input_data = {
        'date': input_date.strftime('%Y-%m-%d'),
        'Gia_Brent(USD)': input_prices['Gia_Brent(USD)'],
        'Gia_WTI(USD)': input_prices['Gia_WTI(USD)'],
        'USD/VND': input_prices['USD/VND'],
        'loai_su_kien': selected_event if selected_event != 'Kh√¥ng c√≥ s·ª± ki·ªán' else np.nan,
        'ten_su_kien': np.nan,
        'tang_giam': sentiment if sentiment != 'None' else np.nan,
    }
    try:
        raw_prediction, _ = predict_raw_input(raw_input_data, df_raw, feature_names, scaler, selected_model)
        diff = raw_prediction - price_context['current_price']
        if diff >= 500:
            col3_sum.error(f"‚ö†Ô∏è D·ª∞ B√ÅO TƒÇNG M·∫†NH (D·ª± ki·∫øn: +{diff:,.0f} VND)")
        elif diff <= -500:
            col3_sum.success(f"‚úÖ D·ª∞ B√ÅO GI·∫¢M M·∫†NH (D·ª± ki·∫øn: {diff:,.0f} VND)")
        else:
            col3_sum.info("·ªîN ƒê·ªäNH: Gi√° d·ª± ki·∫øn thay ƒë·ªïi √≠t.")
    except Exception as e:
        col3_sum.error(f"L·ªói: {e}")

st.markdown("---")

# PH·∫¶N 1: D·ª∞ ƒêO√ÅN SINGLE-STEP
st.header("1Ô∏è‚É£ D·ª± ƒëo√°n Gi√° xƒÉng Ng√†y ti·∫øp theo & Ph√¢n t√≠ch T√°c ƒë·ªông")
col1_pred, col2_pred = st.columns([1, 1])

if col1_pred.button("D·ª± ƒëo√°n Gi√° XƒÉng Single-step", type="primary"):
    selected_model = model_results[model_selection]['model']
    raw_input_data = {
        'date': input_date.strftime('%Y-%m-%d'),
        'Gia_Brent(USD)': input_prices['Gia_Brent(USD)'],
        'Gia_WTI(USD)': input_prices['Gia_WTI(USD)'],
        'USD/VND': input_prices['USD/VND'],
        'loai_su_kien': selected_event if selected_event != 'Kh√¥ng c√≥ s·ª± ki·ªán' else np.nan,
        'ten_su_kien': np.nan,
        'tang_giam': sentiment if sentiment != 'None' else np.nan,
    }
    try:
        raw_prediction, X_predict = predict_raw_input(raw_input_data, df_raw, feature_names, scaler, selected_model)
        col1_pred.success(f"#### Gi√° D·ª± b√°o ({input_date.strftime('%Y-%m-%d')}): **{raw_prediction:,.0f} VND**")
        df_importance = get_feature_importance(selected_model, feature_names)
        if df_importance is not None:
            col2_pred.subheader("Y·∫øu t·ªë T√°c ƒë·ªông L·ªõn nh·∫•t")
            col2_pred.dataframe(df_importance.style.format({'Importance': '{:.4f}'}), use_container_width=True)
        else:
            col2_pred.info("Feature Importance ch·ªâ kh·∫£ d·ª•ng cho c√°c m√¥ h√¨nh c√¢y (Tree-based Models).")
    except Exception as e:
        col1_pred.error(f"L·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n Single-step: {e}")

st.markdown("---")

# PH·∫¶N 2: D·ª∞ B√ÅO ƒê·ªÜ QUY & CI
st.header("2Ô∏è‚É£ D·ª± b√°o T∆∞∆°ng lai & Bi·ªÉu ƒë·ªì Kho·∫£ng tin c·∫≠y")
forecast_days_map = {'7 Ng√†y': 7, '30 Ng√†y': 30, '90 Ng√†y': 90}

if st.button("Ch·∫°y D·ª± b√°o ƒê·ªá quy & Kho·∫£ng tin c·∫≠y", key="run_forecast_btn"):
    st.info("ƒêang ch·∫°y d·ª± b√°o ƒë·ªá quy v√† bootstrap CI...")
    selected_model = model_results[model_selection]['model']
    try:
        # d√πng st l√†m container cho progress bar
        df_forecast = recursive_forecast(df_raw, feature_names, scaler, selected_model, forecast_steps=90, n_bootstraps=30, st_container=st)
        st.subheader("üìà Bi·ªÉu ƒë·ªì D·ª± b√°o D√†i h·∫°n v·ªõi Kho·∫£ng Tin c·∫≠y 95%")
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(df_forecast.index, df_forecast['Gi√° D·ª± b√°o'], label='Gi√° D·ª± b√°o')
        ax.fill_between(df_forecast.index, df_forecast['CI 95% Min'], df_forecast['CI 95% Max'], alpha=0.1, label='Kho·∫£ng Tin c·∫≠y 95%')
        ax.set_title(f"D·ª± b√°o Gi√° RON 95-III - {model_selection}")
        ax.set_xlabel("Ng√†y")
        ax.set_ylabel("Gi√° (VND)")
        ax.tick_params(axis='x', rotation=45)
        ax.legend()
        ax.grid(True, linestyle='--', alpha=0.6)
        st.pyplot(fig)

        st.subheader("üìù T√≥m t·∫Øt Gi√° D·ª± b√°o Ng·∫Øn h·∫°n")
        summary_data = []
        for label, days in forecast_days_map.items():
            if days <= len(df_forecast):
                final_row = df_forecast.iloc[days - 1]
                summary_data.append({
                    'Th·ªùi gian': label,
                    'Ng√†y d·ª± b√°o cu·ªëi': df_forecast.index[days - 1].strftime('%Y-%m-%d'),
                    'Gi√° D·ª± b√°o': f"{final_row['Gi√° D·ª± b√°o']:,.0f} VND",
                    'CI 95%': f"[{final_row['CI 95% Min']:,.0f} - {final_row['CI 95% Max']:,.0f}] VND"
                })
        if summary_data:
            st.table(pd.DataFrame(summary_data))
        else:
            st.write("Kh√¥ng ƒë·ªß b∆∞·ªõc d·ª± b√°o ƒë·ªÉ t√≥m t·∫Øt.")
    except Exception as e:
        st.error(f"L·ªói khi ch·∫°y d·ª± b√°o ƒë·ªá quy: {e}")

st.markdown("---")

# PH·∫¶N 3: BI·ªÇU ƒê·ªí L·ªäCH S·ª¨
st.header("3Ô∏è‚É£ Bi·∫øn ƒë·ªông Gi√° L·ªãch s·ª≠ (6 Th√°ng / 1 NƒÉm)")
col1_hist, col2_hist = st.columns(2)

if col1_hist.button("Xem Bi·∫øn ƒë·ªông 6 Th√°ng", key='run_6m_hist_btn'):
    fig_6m, _ = plot_historical_trends(df_raw, days=180)
    col1_hist.subheader("Bi·∫øn ƒë·ªông 6 Th√°ng")
    col1_hist.pyplot(fig_6m)

if col2_hist.button("Xem Bi·∫øn ƒë·ªông 1 NƒÉm", key='run_1y_hist_btn'):
    fig_1y, _ = plot_historical_trends(df_raw, days=365)
    col2_hist.subheader("Bi·∫øn ƒë·ªông 1 NƒÉm")
    col2_hist.pyplot(fig_1y)
